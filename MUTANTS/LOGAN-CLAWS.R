##############
# LOGAN-CLAWS
# Light Output Generated by AstroNomical objects - Creating fiLes And Writing to Storage
# This code generates from an object the expected output files
# These files are 
#       1) a .fits (INPUT) file with a table which includes the spectra and the fotometry in the header
#       2) a .fits (LABEL) file with the SFR generated (Solution)
# First, the data is recollected, then the additional headers are created, the main header is generated,
# and finally the file is saved.

# extraHeader format: list with elements: "keyword", "value", "note"
# spectrumParam format: idem extraHeader, exclusive for parameters for Spectrum

#####
# Load required libraries
library(FITSio)
library(ProSpect)
library(uuid)
library(rlist)
library(reticulate)

'%!in%' <- function(x,y)!('%in%'(x,y))

simple.two.axes.plot <- function(lx, ly, rx, ry, xlab=NULL, lylab=NULL, rylab=NULL, main="",
                                 ltype="l", rtype="p", lpch=1, rpch=17, lcol="black", rcol="red", xlim=NULL){
  if (is.null(xlim)){
    xlim = c(min(c(lx, rx)), max(c(lx, rx)))
  }
  par(mar = c(5, 4, 4, 4) + 0.3)  # Leave space for z axis
  plot(lx, ly, type=ltype, xlim=xlim,
       main=main, xlab=xlab, ylab=lylab, pch=lpch, col=lcol) # first plot
  par(new = TRUE)
  plot(rx, ry, pch=rpch, axes = FALSE, bty = "n", xlab = "", ylab = "", col=rcol, xlim=xlim)
  axis(side=4, at = pretty(range(ry)), col=rcol, col.axis=rcol)
  mtext("magnitudes", side=4, line=3, col=rcol)
}


exportObjectsToSingleFITS <- function(Parameters,
                                      df,
                                      inputMatrix,
                                      labelMatrix,
                                      filename,
                                      foldername,
                                      filters,
                                      fileprefix= "",
                                      absolutePath = FALSE,
                                      saveDataFrame=FALSE,
                                      verbose=2,
                                      time_taken=NULL
                                     ){
  #####
  # Function(s)
  # Adds the Filters to the header
  addFiltersToHeaderSingle <- function(header, filters){
    header <- addComment("------ List of filters analysed ------", header=header)
    for (i in 1:length(filters$filter)){
      header <- addKwv(paste0("filterN", i),
                       filters$filter[i],
                       note=paste("Filter Name", i),
                       header=header)
      header <- addKwv(paste0("filterC", i),
                       filters$cenwave[i],
                       note=paste("Filter CenterWave", i),
                       header=header)
    }
    return(header)
  }
  
  
  #####
  # Read and generate data + metadata
  objectUUID = UUIDgenerate(n=3L)
  dateGenerated = Sys.time()
  n.filters = length(filters$filter)
  spectra.points = dim(inputMatrix)[2] - 1 - n.filters
  n.agevec = (dim(labelMatrix)[2] - 1)/2
  
  
  #####
  # Generate Header for Inputs
  # R saves scientific notation with lower case 'e'. Will be fixed in python.
  hdrIn <- newKwv("DateGen", dateGenerated, "Date when generated")
  hdrIn <- addKwv("FileType", "Input", note="File type (Input/Label)", header=hdrIn)
  hdrIn <- addKwv("Filename", paste0("Input_", fileprefix, filename, ".fits"), header=hdrIn)
  hdrIn <- addKwv("UuidInp", objectUUID[1], note="UUID for Input", header=hdrIn)
  hdrIn <- addKwv("UuidLab", objectUUID[2], note="UUID for Label", header=hdrIn)
  hdrIn <- addKwv("UuidMet", objectUUID[3], note="UUID for Metadata", header=hdrIn)
  hdrIn <- addFiltersToHeaderSingle(hdrIn, filters)
  hdrIn <- addKwv("NSpectra", spectra.points,note="Number of SpectraPoints", header=hdrIn)
  hdrIn <- addKwv("NFilters", n.filters, note="Number of Filters", header=hdrIn)
  hdrIn <- addKwv("NRows", dim(inputMatrix)[1] - 1, note="Number of Rows", header=hdrIn)
  hdrIn <- addComment("First row (ID=0) has the X values of corresponding column", hdrIn)
  
  
  #####
  # Generate Header for Labels
  # R saves scientific notation with lower case 'e'. Will be fixed in python.
  hdrLb <- newKwv("DateGen", dateGenerated, "Date when generated")
  hdrLb <- addKwv("FileType", "Label", note="File type [Input/Label]", header=hdrLb)
  hdrLb <- addKwv("Filename", paste0("Label_", fileprefix, filename, ".fits"), header=hdrLb)
  hdrLb <- addKwv("UuidInp", objectUUID[1], note="UUID for Input", header=hdrLb)
  hdrLb <- addKwv("UuidLab", objectUUID[2], note="UUID for Label", header=hdrLb)
  hdrLb <- addKwv("UuidMet", objectUUID[3], note="UUID for Metadata", header=hdrLb)  
  hdrLb <- addKwv("Nagevec", n.agevec, note="Length of agevec", header=hdrLb)
  hdrLb <- addComment("First row (ID=0) has the X values of corresponding column", hdrLb)

  
  #####
  # Generate File Names and verify directory
  if (absolutePath){
    filedirectory = foldername
  } else {
    filedirectory = file.path(getwd(), foldername)
  }
  filename = paste0(fileprefix, filename, ".fits")
  
  # If output folder does not exist, generate it
  dir.create(filedirectory, showWarnings = FALSE)
  if (verbose >= 1)
    cat("Saving files in '", filedirectory, "/'.\n", sep="")
  
  
  #####
  # Save files
  if (verbose >= 1)
    cat(paste0("Saving Input_", filename, " ...\n"))
  writeFITSim(inputMatrix,
              file = paste0(filedirectory, "/Input_", filename),
              header=hdrIn)
  
  if (verbose >= 1)
    cat(paste0("Saving Label_", filename, " ...\n"))
  writeFITSim(labelMatrix,
              file = paste0(filedirectory, "/Label_", filename),
              header=hdrLb)
  
  
  #####
  # Calculate time elapsed
  write_checkpoint = Sys.time()
  time_taken = c(time_taken, list(write_checkpoint=write_checkpoint))
  timeElapsed = list(
    Init=(time_taken$init_checkpoint - time_taken$start_time)[[1]],
    dataframe=(time_taken$df_checkpoint - time_taken$init_checkpoint)[[1]],
    draw=(time_taken$draw_checkpoint - time_taken$df_checkpoint)[[1]],
    spectra=(time_taken$spectra_checkpoint - time_taken$draw_checkpoint)[[1]],
    write=(time_taken$write_checkpoint - time_taken$spectra_checkpoint)[[1]],
    total=(time_taken$write_checkpoint - time_taken$start_time)[[1]]
  )
  
  if (verbose >= 1)
    cat(paste0("Saving MetaD_", filename, " ...\n"))
  metadata=list(Parameters=Parameters[-which(names(Parameters)=="speclib")],
                extra=list(UUIDINP=objectUUID[1],
                           UUIDLAB=objectUUID[2],
                           UUIDMET=objectUUID[3],
                           date=Sys.time()
                           ),
                ElapsedTime=timeElapsed
                )
  if (saveDataFrame){
    metadata[["df"]]=df
  }
  
  save(metadata, file=paste0(filedirectory, "/MetaD_", substr(filename, 1, nchar(filename) - 5), ".rda"))
  
  # Return metadata object
  return(metadata)
}


interpolateToWaveout <- function(x1,
                                 y1,
                                 waveout,
                                 returnList = FALSE,
                                 offset = 0.5,
                                 n.points.integrate = 50,
                                 interpolate = FALSE,
                                 method.to.evaluate = "mean") {
  if (interpolate) {
    # If interpolate is TRUE, simply interpolate for the xnew (waveout).
    # This is NOT ADVISED if the NEW RESOLUTION IS SMALLER.
    waveoutL = log10(waveout)
    x1L = log10(x1)
    y1L = log10(y1)
    spect = 10 ^ approxfun(x1L, y1L, rule = 2)(waveoutL)
    if (!returnList) {
      return(spect)
    } else {
      return(list(wave = waveout, spect = spect))
    }
  } else {
    # If interpolate is FALSE, calculate the average values for the points for the new x
    
    # offset calculates where the bin limits will be placed:
    # the centerpoint c_i between two consecutive points (x_i and x_i+1, with x_i+1 > x_i) will be placed at
    # c_i <- (x_i+1 - x_i+1) * offset + x_i
    # the new evaluation will be:
    # y_i <- index in data where value corresponds to x=c_i
    # f_new(x_i) <- mean(data[y_i-1 : y_i])
    
    if (offset < 0 || offset > 1) {
      stop("'offset' needs to be within [0,1]")
    }
    
    # Initialize Y
    last.w = length(waveout)
    newy = numeric(last.w)
    
    # Iterate over every new waveout and define limits for integration
    for (i in 1:last.w) {
      # Separate between first, last and rest
      if (i == 1) {
        left  = waveout[1] -
          (waveout[2] - waveout[1]) * (1 - offset)
        right = waveout[1] +
          (waveout[2] - waveout[1]) * offset
        
      } else if (i == last.w) {
        left  = waveout[last.w - 1] + 
          (waveout[last.w] - waveout[last.w - 1]) * offset
        right = waveout[last.w] + 
          (waveout[last.w] - waveout[last.w -1]) * offset
        
      } else {
        left  = waveout[i - 1] +
          (waveout[i] - waveout[i - 1]) * offset
        right = waveout[i]   +
          (waveout[i + 1] - waveout[i]) * offset
      }
      
      # Once we know the limits between which we need to integrate,
      # interpolate a higher resolution (n.points.integrate) x vector
      # and interpolate the new values (using logs).
      tmp = interpolateToWaveout(x1,
                                 y1,
                                 seq(left, right, length.out = n.points.integrate),
                                 interpolate = TRUE)
      
      # Obtain the final value from this vector (mean/median)
      if (method.to.evaluate == "mean") {
        newy[i] = mean(tmp)
      } else if (method.to.evaluate == "median") {
        newy[i] = median(tmp)
      }
    }
    
    if (!returnList) {
      return(newy)
    } else {
      return(list(wave = waveout, flux = newy))
    }
  }
}

convertAgevecToOutputScale <- function(agevector,
                                       datavector,
                                       new_scale=NULL,
                                       max.age=13.8e9,
                                       n.splits=10,
                                       method="mean",
                                       return_scale=FALSE) {
  # Converts Agevector (based on the Library [EMILESCombined]) to a smaller vector (for the CNN output).
  if (new_scale == "defaultlog1" || is.null(new_scale)) {
    new_scale = c(0, 6.3, 7.9, 10, 12.6, 15.8, 20, 25.1, 31.6, 39.8, 50.1, 63.1, 70.8,
                  130, 255, 510, 900, 1800, 3200, 6400, 12600)
  } else if (new_scale == "defaultlog2") {
    new_scale = c(0, 10, 32, 50.5, 130, 255, 510, 900, 1800, 3200, 6400, 12600)
  } else if (new_scale == "lovell"){
    new_scale = c(0, 32, 68, 147, 316, 681, 1470, 3160, 12460)
  } else if (new_scale == "newlog") {
    # Separate into n.splits bins (log)
    agevec.below.max = agevector[agevector<max.age]
    log_agevec = log10(agevec.below.max)
    
    # Split homogeneously among the values
    age_split <- split(agevec.below.max, cut(seq_along(log_agevec), n.splits, labels = FALSE))
    
    # Keep the last value (this gives the max value for the bin)
    new_scale = c(0)
    for (i in 1:length(age_split)){
      new_scale = c(new_scale, age_split[[i]][length(age_split[[i]])]/1000000)
    }
  } # ToDo: Maybe a 3rd default value that uses 
  
  # Identify which values of the agevector should go in each bin. NA if a value is above the max value (las element in new_scale)
  separations <- cut(as.matrix(agevector), new_scale * 1000000, labels = FALSE, include.lowest = TRUE)
  
  # Separate the data according to the x value
  data_groups <- suppressWarnings(split(datavector, separations))
  age_groups <- suppressWarnings(split(agevector, separations))

  # Consolidate the data using mean or median
  out <- c()
  age <- c()
  width <- c()
  for (i in 1:length(data_groups)) {
    # First, get the data into the new bins
    if (method == "mean") {
      tmp <- mean(data_groups[[i]])
    } else if (method == "median") {
      tmp <- median(data_groups[[i]])
    }
    out <- c(out, tmp)
    width <- c(width, length(age_groups[[i]]))
    
    # Second, get the ages of the bins
    age <- c(age, 10^mean(log10(age_groups[[i]])))

  }
  if (return_scale){
    output = list(age=age, data=out, width=width, new_scale=new_scale)
  } else {
    output = list(age=age, data=out, width=width)
  }
  return(output)
}



draw_SFH_cases <- function(metadata_file,
                           output_file_name,
                           n.simul = 0.4,
                           age = NULL,           
                           agestart = 1e6,
                           ageend = 13.8e9,
                           agestep = 1e6,
                           opacity="normal",
                           color=NULL,
                           log=NULL,
                           verbose=0,
                           y.lim=NULL,
                           image.size=c(1920, 1080)
                           ){
  # Load data
  metadata <- list.load(metadata_file)
  combined = "Combined" %in% names(metadata)
  constante.opacidad = 1
  
  # Get Age parameters
  if (is.null(age)){
    age = seq(agestart, ageend, agestep)
  }
  
  # get number of total cases
  if (combined){
    n.cases = metadata$Last_ID[length(metadata$Last_ID)]
  } else {
    n.cases = metadata$totalCases
  }
  
  # Import Python library
  erik <- import_from_path("ERIK", path="MUTANTS/")
  
  # Define indices that will be calculated
  # possible values for n.simul:
  #     n.simul >=  1     ==> n.simul random indices
  #     n.simul ==  0     ==> every single case (NOT RECOMMENDED)
  #     0 < n.simul < 1   ==> int(n.cases * n.simul) cases
  if (n.simul >= 1){
    random_values = sample(n.cases, n.simul)
  } else if (n.simul == 0){
    random_values = sample(n.cases, n.cases)
  } else if (0 < n.simul && n.simul < 1){
    random_values = sample(n.cases, as.integer(n.cases * n.simul))
  } else {
    stop(paste0("n.simul does not have a valid value: ", n.simul, "\n"))
  }
  cat(paste0("n=", length(random_values), "\n"))
  
  # Set opacity
  if (is.null(color)){
    if (opacity == "normal"){
      opacity = constante.opacidad/length(random_values)
      color = rgb(0, 0, 255, max = 255, alpha = max(opacity, 1), names = "bluelight")
    }
  }
  
  
  # Initialize plot
  png(filename=output_file_name, width=image.size[1], height=image.size[2])
  list_parameters <- erik$getparametersfromid(metadata_file, random_values[1], returnfunction=TRUE)
  func = paste0("massfunc_", list_parameters$massfunction)
  args <- formalArgs(func)
  args <- args[args %in% names(list_parameters)]
  y <- do.call(func, c(list(age=age), list_parameters[args]))
  plot(age, y, type="l", log=log, col=color, main=paste(metadata_file, "n=", length(random_values)), ylim=y.lim)
  
  # Iterate over the different values and plot
  for (idx in 2:length(random_values)){
    if (verbose > 0){
      if ((idx %% 100) == 1){
        cat(paste0(idx, "/", length(random_values), "\n"))
      }
    }
    list_parameters <- erik$getparametersfromid(metadata_file, random_values[idx], returnfunction=TRUE)
    func = paste0("massfunc_", list_parameters$massfunction)
    args <- formalArgs(func)
    args <- args[args %in% names(list_parameters)]
    y <- do.call(func, c(list(age=age), list_parameters[args]))
    lines(age, y, col=color)
  }
  dev.off()
  return(metadata) 
}


# ToDo: Remove this in the end
if (FALSE){
metadata_file = "/Volumes/Elements/Outputs/MetaD_combined.json"
n.simul = 100

func = massfunc_dtau

metadata <- list.load(metadata_file)
metadata2 <- list.load(metadata_file2)


list_parameters$mfunction
t = ""
for (j in list_parameters$mfunction){
  t = paste0(t, j)
}
t = parse(t)

setwd("~/Documents/GitHub/LOGAN-SFH")
EMILESCombined = readRDS(file="EMILESData/EMILESCombined.rds")

}

if (FALSE){
setwd("~/Documents/GitHub/LOGAN-SFH")
EMILESCombined = readRDS(file="EMILESData/EMILESCombined.rds")
metadata = draw_SFH_cases("/Volumes/Elements/Outputs/MetaD_combined.json",
                          "/Volumes/Elements/Outputs/MetaD_combined_plots.png",
                          0,
                          age=EMILESCombined$Age,
                          log="x",
                          y.lim=c(0, 10),
                          verbose=1,
                          image.size = c(3840, 2160)
                          )

}
